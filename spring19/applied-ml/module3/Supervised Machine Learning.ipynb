{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "attributes = data.feature_names[:5]\n",
    "scatter_matrix(X[attributes], figsize = (15,15), c = y, alpha = 0.8, marker = 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_area = X.iloc[:,3]\n",
    "\n",
    "plt.scatter(X_area, y, c = y)\n",
    "plt.xlabel('Mean Area')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.2)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test = scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "train_score_array = []\n",
    "test_score_array = []\n",
    "\n",
    "for k in range(1,20):\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score_array.append(knn.score(X_train, y_train))\n",
    "    test_score_array.append(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = range(1,20)\n",
    "%matplotlib inline\n",
    "plt.plot(x_axis, train_score_array, label = 'Train Score', c = 'g')\n",
    "plt.plot(x_axis, test_score_array, label = 'Test Score', c='b')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems k = 10 is the best parameter for knn model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(10)\n",
    "knn.fit(X_train, y_train)\n",
    "print('Train score: {:.4f}'.format(knn.score(X_train, y_train)))\n",
    "print('Train score: {:.4f}'.format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "X_b = X_train[100:150,[2,5]]\n",
    "y_b = y_train[100:150]\n",
    "\n",
    "knn = KNeighborsClassifier(10)\n",
    "knn.fit(X_b, y_b) \n",
    "\n",
    "mglearn.plots.plot_2d_separator(knn, X_b, fill=True, eps=0.5, alpha=.4)\n",
    "mglearn.discrete_scatter(X_b[:, 0], X_b[:, 1], y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Neighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "attributes = data.feature_names[:5]\n",
    "scatter_matrix(X[attributes], figsize = (15,15), c = y, alpha = 0.8, marker = 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X,y, random_state = 0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test = scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "train_score_array = []\n",
    "test_score_array = []\n",
    "\n",
    "for k in range(1,10):\n",
    "    knn_reg = KNeighborsRegressor(k)\n",
    "    knn_reg.fit(X_train, y_train)\n",
    "    train_score_array.append(knn_reg.score(X_train, y_train))\n",
    "    test_score_array.append(knn_reg.score(X_test, y_test))\n",
    "\n",
    "x_axis = range(1,10)\n",
    "plt.plot(x_axis, train_score_array, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_axis, test_score_array, c = 'b', label = 'Test Score')\n",
    "plt.legend()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('RSQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRIM and AGE\n",
    "X_b = X_train[:50,6].reshape(-1,1)\n",
    "y_b = y_train[:50]\n",
    "\n",
    "knn_reg = KNeighborsRegressor(1)\n",
    "knn_reg.fit(X_b, y_b)\n",
    "\n",
    "X_new=np.linspace(X_b.min(), X_b.max(), 50).reshape(50, 1)\n",
    "y_predict = knn_reg.predict(X_new)\n",
    "\n",
    "plt.plot(X_new, y_predict, c = 'r')\n",
    "plt.scatter(X_b, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using the Normal Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "data = load_boston()\n",
    "\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X,y, random_state = 0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test = scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7697699488741149\n",
      "0.6354638433202122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train, y_train)\n",
    "print(lreg.score(X_train, y_train))\n",
    "print(lreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'RM')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train_rm = X_train[:,5].reshape(-1,1)\n",
    "lreg.fit(X_train_rm, y_train)\n",
    "y_predict = lreg.predict(X_train_rm)\n",
    "\n",
    "plt.plot(X_train_rm, y_predict, c = 'r')\n",
    "plt.scatter(X_train_rm,y_train)\n",
    "plt.xlabel('RM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(random_state= 0, max_iter = 100000, learning_rate = 'optimal', penalty = 'l2')\n",
    "sgd_reg.fit(X_train, y_train)\n",
    "print(sgd_reg.score(X_train, y_train))\n",
    "print(sgd_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.preprocessing  import PolynomialFeatures\n",
    "\n",
    "X_train_1 = X_train[:,5].reshape(-1,1)\n",
    "plt.scatter(X_train_1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "for n in range(1,3):\n",
    "    poly = PolynomialFeatures(n)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    lreg.fit(X_train_poly, y_train)\n",
    "    train_score_list.append(lreg.score(X_train_poly, y_train))\n",
    "    test_score_list.append(lreg.score(X_test_poly, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_score_list)\n",
    "print(test_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "x_axis = range(1,3)\n",
    "plt.plot(x_axis, train_score_list, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_axis, test_score_list, c = 'b', label = 'Test Score')\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(n)\n",
    "X_train_poly = poly.fit_transform(X_train_1)\n",
    "lreg.fit(X_train_poly, y_train)\n",
    "\n",
    "x_axis = np.linspace(0,1,100).reshape(-1,1)\n",
    "x_poly = poly.transform(x_axis)\n",
    "y_predict = lreg.predict(x_poly)\n",
    "\n",
    "X_train_1 = X_train[:,5].reshape(-1,1)\n",
    "plt.scatter(X_train_1,y_train)\n",
    "plt.plot(x_axis, y_predict, c = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.linear_model import Ridge\n",
    "\n",
    "x_range = [0.01, 0.1, 1, 10, 100]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "for alpha in x_range: \n",
    "    ridge = Ridge(alpha)\n",
    "    ridge.fit(X_train,y_train)\n",
    "    train_score_list.append(ridge.score(X_train,y_train))\n",
    "    test_score_list.append(ridge.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_range, train_score_list, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_range, test_score_list, c = 'b', label = 'Test Score')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc = 3)\n",
    "plt.xlabel(r'$\\alpha$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that the best $\\alpha$ parameter is 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_score_list)\n",
    "print(test_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha = 0.001)\n",
    "ridge.fit(X_train,y_train)\n",
    "print('Train score: {:.4f}'.format(ridge.score(X_train,y_train)))\n",
    "print('Test score: {:.4f}'.format(ridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "x_range1 = np.linspace(0.001, 1, 100).reshape(-1,1)\n",
    "x_range2 = np.linspace(1, 10000, 10000).reshape(-1,1)\n",
    "\n",
    "x_range = np.append(x_range1, x_range2)\n",
    "coeff = []\n",
    "\n",
    "for alpha in x_range: \n",
    "    ridge = Ridge(alpha)\n",
    "    ridge.fit(X_train,y_train)\n",
    "    coeff.append(ridge.coef_ )\n",
    "    \n",
    "coeff = np.array(coeff)\n",
    "\n",
    "for i in range(0,13):\n",
    "    plt.plot(x_range, coeff[:,i], label = 'feature {:d}'.format(i))\n",
    "\n",
    "plt.axhline(y=0, xmin=0.001, xmax=9999, linewidth=1, c ='gray')\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.5),\n",
    "          ncol=3, fancybox=True, shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "x_range = [0.01, 0.1, 1, 10, 100]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "for alpha in x_range: \n",
    "    lasso = Lasso(alpha)\n",
    "    lasso.fit(X_train,y_train)\n",
    "    train_score_list.append(lasso.score(X_train,y_train))\n",
    "    test_score_list.append(lasso.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_range, train_score_list, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_range, test_score_list, c = 'b', label = 'Test Score')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc = 3)\n",
    "plt.xlabel(r'$\\alpha$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "x_range1 = np.linspace(0.001, 1, 1000).reshape(-1,1)\n",
    "x_range2 = np.linspace(1, 1000, 1000).reshape(-1,1)\n",
    "\n",
    "x_range = np.append(x_range1, x_range2)\n",
    "coeff = []\n",
    "\n",
    "for alpha in x_range: \n",
    "    lasso = Lasso(alpha)\n",
    "    lasso.fit(X_train,y_train)\n",
    "    coeff.append(lasso.coef_ )\n",
    "    \n",
    "coeff = np.array(coeff)\n",
    "\n",
    "for i in range(0,13):\n",
    "    plt.plot(x_range, coeff[:,i], label = 'feature {:d}'.format(i))\n",
    "\n",
    "plt.axhline(y=0, xmin=0.001, xmax=9999, linewidth=1, c ='gray')\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.5),\n",
    "          ncol=3, fancybox=True, shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.2)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test = scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "c_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "train_score_l1 = []\n",
    "train_score_l2 = []\n",
    "test_score_l1 = []\n",
    "test_score_l2 = []\n",
    "\n",
    "for c in c_range:\n",
    "    log_l1 = LogisticRegression(penalty = 'l1', C = c)\n",
    "    log_l2 = LogisticRegression(penalty = 'l2', C = c)\n",
    "    log_l1.fit(X_train, y_train)\n",
    "    log_l2.fit(X_train, y_train)\n",
    "    train_score_l1.append(log_l1.score(X_train, y_train))\n",
    "    train_score_l2.append(log_l2.score(X_train, y_train))\n",
    "    test_score_l1.append(log_l1.score(X_test, y_test))\n",
    "    test_score_l2.append(log_l2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(c_range, train_score_l1, label = 'Train score, penalty = l1')\n",
    "plt.plot(c_range, test_score_l1, label = 'Test score, penalty = l1')\n",
    "plt.plot(c_range, train_score_l2, label = 'Train score, penalty = l2')\n",
    "plt.plot(c_range, test_score_l2, label = 'Test score, penalty = l2')\n",
    "plt.legend()\n",
    "plt.xlabel('Regularization parameter: C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import mglearn\n",
    "X_b = X_train[10:50, [1,3]]\n",
    "y_b = y_train[10:50]\n",
    "\n",
    "lreg = LogisticRegression()\n",
    "lreg.fit(X_b, y_b) \n",
    "\n",
    "mglearn.plots.plot_2d_separator(lreg, X_b, fill=True, eps=0.5, alpha=.4)\n",
    "mglearn.discrete_scatter(X_b[:, 0], X_b[:, 1], y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10)\n",
    "softmax_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_reg.predict([[5, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_reg.predict_proba([[5, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(0, 8, 500).reshape(-1, 1),\n",
    "        np.linspace(0, 3.5, 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "\n",
    "\n",
    "y_proba = softmax_reg.predict_proba(X_new)\n",
    "y_predict = softmax_reg.predict(X_new)\n",
    "\n",
    "zz1 = y_proba[:, 1].reshape(x0.shape)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==2, 0], X[y==2, 1], \"g^\", label=\"Iris-Virginica\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"bs\", label=\"Iris-Versicolor\")\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"center left\", fontsize=14)\n",
    "plt.axis([0, 7, 0, 3.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import mglearn\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = iris[\"target\"]\n",
    "\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.legend(['Setosa', 'Versicolor', 'Virginica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svm = LinearSVC().fit(X_train, y_train)\n",
    "print(\"Coefficient shape: \", linear_svm.coef_.shape)\n",
    "print(\"Intercept shape: \", linear_svm.intercept_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "line = np.linspace(-15, 15)\n",
    "for coef, intercept, color in zip(linear_svm.coef_, linear_svm.intercept_,\n",
    "                                  mglearn.cm3.colors):\n",
    "    plt.plot(line, -(line * coef[0] + intercept) / coef[1], c=color)\n",
    "plt.ylim(-5, 5)\n",
    "plt.xlim(0, 8)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.legend(['Class 0', 'Class 1', 'Class 2', 'Line class 0', 'Line class 1',\n",
    "            'Line class 2'], loc=(1.01, 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC with kernel trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: data to base x-axis meshgrid on\n",
    "    y: data to base y-axis meshgrid on\n",
    "    h: stepsize for meshgrid, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xx, yy : ndarray\n",
    "    \"\"\"\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axes object\n",
    "    clf: a classifier\n",
    "    xx: meshgrid ndarray\n",
    "    yy: meshgrid ndarray\n",
    "    params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data[:, 2:]\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "C = 1.0  \n",
    "models = (SVC(kernel='linear', C=C),\n",
    "          LinearSVC(C=C),\n",
    "          SVC(kernel='rbf', gamma=0.7, C=C),\n",
    "          SVC(kernel='poly', degree=3, C=C))\n",
    "\n",
    "models = (clf.fit(X_train, y_train) for clf in models)\n",
    "\n",
    "# title for the plots\n",
    "titles = ('SVC with linear kernel',\n",
    "          'LinearSVC (linear kernel)',\n",
    "          'SVC with RBF kernel',\n",
    "          'SVC with polynomial (degree 3) kernel')\n",
    "\n",
    "# Set-up 2x2 grid for plotting.\n",
    "fig, sub = plt.subplots(2, 2)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "X0, X1 = X_train[:, 0], X_train[:, 1]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "for clf, title, ax in zip(models, titles, sub.flatten()):\n",
    "    plot_contours(ax, clf, xx, yy,\n",
    "                  cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    ax.scatter(X0, X1, c=y_train, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xlabel('Petal length')\n",
    "    ax.set_ylabel('Petal width')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data[:, 2:]\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "\n",
    "models = (SVC(kernel='rbf', gamma=0.01, C=1),\n",
    "         SVC(kernel = 'rbf', gamma = 0.1, C = 1),\n",
    "         SVC(kernel = 'rbf', gamma = 1, C = 1),\n",
    "         SVC(kernel = 'rbf', gamma = 10, C = 1))\n",
    "\n",
    "\n",
    "models = (clf.fit(X_train, y_train) for clf in models)\n",
    "\n",
    "# title for the plots\n",
    "titles = (r'$\\gamma$ = 0.01',\n",
    "          r'$\\gamma$ = 0.1',\n",
    "          r'$\\gamma$ = 1',\n",
    "          r'$\\gamma$ = 10')\n",
    "\n",
    "# Set-up 2x2 grid for plotting.\n",
    "fig, sub = plt.subplots(2, 2)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "X0, X1 = X_train[:, 0], X_train[:, 1]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "for clf, title, ax in zip(models, titles, sub.flatten()):\n",
    "    plot_contours(ax, clf, xx, yy,\n",
    "                  cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    ax.scatter(X0, X1, c=y_train, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xlabel('Petal length')\n",
    "    ax.set_ylabel('Petal width')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data[:, 2:]\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "\n",
    "models = (SVC(kernel='rbf', gamma=0.7, C=0.01),\n",
    "         SVC(kernel = 'rbf', gamma = 0.7, C = 0.1),\n",
    "         SVC(kernel = 'rbf', gamma = 0.7, C = 1),\n",
    "         SVC(kernel = 'rbf', gamma = 0.7, C = 10))\n",
    "\n",
    "\n",
    "models = (clf.fit(X_train, y_train) for clf in models)\n",
    "\n",
    "# title for the plots\n",
    "titles = (r'$\\gamma$ = 0.01',\n",
    "          r'$\\gamma$ = 0.1',\n",
    "          r'$\\gamma$ = 1',\n",
    "          r'$\\gamma$ = 10')\n",
    "\n",
    "# Set-up 2x2 grid for plotting.\n",
    "fig, sub = plt.subplots(2, 2)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "X0, X1 = X_train[:, 0], X_train[:, 1]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "for clf, title, ax in zip(models, titles, sub.flatten()):\n",
    "    plot_contours(ax, clf, xx, yy,\n",
    "                  cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    ax.scatter(X0, X1, c=y_train, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xlabel('Petal length')\n",
    "    ax.set_ylabel('Petal width')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=0)\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "dtree.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dtree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dtree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dtree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dtree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_feature_importances_cancer(model):\n",
    "    n_features = cancer.data.shape[1]\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), cancer.feature_names)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "plot_feature_importances_cancer(dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os     \n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "# Create DOT data\n",
    "from sklearn.tree import export_graphviz\n",
    "dot_data = export_graphviz(dtree, out_file=None, filled=True, rounded=True, special_characters=True)\n",
    "\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_b =  X_train[:50,[2,7]]\n",
    "y_b = y_train[:50]\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_b, y_b)\n",
    "\n",
    "mglearn.plots.plot_2d_separator(dtree, X_b, fill=True, eps=0.5, alpha=.4)\n",
    "mglearn.discrete_scatter(X_b[:, 0], X_b[:, 1], y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor\n",
    "\n",
    "Dataset of historical computer memory (RAM) prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "ram_prices = pd.read_csv(os.path.join(mglearn.datasets.DATA_PATH,\n",
    "                                      \"ram_price.csv\"))\n",
    "\n",
    "plt.semilogy(ram_prices.date, ram_prices.price)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Price in $/Mbyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# use historical data to forecast prices after the year 2000\n",
    "data_train = ram_prices[ram_prices.date < 2000]\n",
    "data_test = ram_prices[ram_prices.date >= 2000]\n",
    "\n",
    "# predict prices based on date\n",
    "X_train = data_train.date[:, np.newaxis]\n",
    "# we use a log-transform to get a simpler relationship of data to target\n",
    "y_train = np.log(data_train.price)\n",
    "\n",
    "tree = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "linear_reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# predict on all data\n",
    "X_all = ram_prices.date[:, np.newaxis]\n",
    "\n",
    "pred_tree = tree.predict(X_all)\n",
    "pred_lr = linear_reg.predict(X_all)\n",
    "\n",
    "# undo log-transform\n",
    "price_tree = np.exp(pred_tree)\n",
    "price_lr = np.exp(pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.semilogy(data_train.date, data_train.price, label=\"Training data\")\n",
    "plt.semilogy(data_test.date, data_test.price, label=\"Test data\")\n",
    "plt.semilogy(ram_prices.date, price_tree, label=\"Tree prediction\")\n",
    "plt.semilogy(ram_prices.date, price_lr, label=\"Linear prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
