{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Tasks\n",
    "- In the dataframe creates in Lab 2 - Part a set ``Salary`` as the target value. \n",
    "- The rest of the columns are considered as X, feature set. \n",
    "- Use ``train_test_split`` to split the dataset into train and test dataset. set ``random_state = 0``.\n",
    "- Use ``MinMaxScaler`` to scale feature set X. \n",
    "\n",
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data != ' ?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['workclass', 'education', 'occupation', 'native-country']\n",
    "data.drop(l, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data['marital-status'])\n",
    "data = pd.concat([data, df], axis = 1)\n",
    "data.drop('marital-status', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data['relationship'])\n",
    "data = pd.concat([data, df], axis = 1)\n",
    "data.drop('relationship', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data['race'])\n",
    "data = pd.concat([data, df], axis = 1)\n",
    "data.drop('race', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sex'] = data['sex'].map({' Male':0, ' Female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Salary'] = data['Salary'].map({' <=50K':0, ' >50K':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Salary']\n",
    "X = data.drop(['Salary'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "Use PCA is to reduce the size of the feature space while retaining 95% of explained variance. What is the size of the transformed feature space? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "For the rest of this lab, we will consider reduced train and test sets. For models with hyper-parameter ``random_state = 0``. \n",
    "\n",
    "Use grid search to find the best parameters of a support vector machine with kernel ``'rbf'`` and following range of parameters: \n",
    "```Python\n",
    "C in [0.1, 1, 10]\n",
    "gamma in [0.1, 1, 10]\n",
    "cv = 5```\n",
    "\n",
    "What are the best parameters of this model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "Train a gradient boosting machine learning model on this dataset with the following hyper-parameters. \n",
    "```Python\n",
    "n_estimators= 100\n",
    "learning_rate=0.5\n",
    "random_state = 0\n",
    "```\n",
    "\n",
    "What is the auc score of test set? (2 significant digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "Using the model created for previous questions, call ``predict_proba`` on the test set. Now change the threshold from 0.5 to 0.75, which means if the probability of an instance belongs to class 0 is higher than or equal to 0.75, then the prediction is label 0, otherwise is label 1. \n",
    "\n",
    "Now, what is the auc score of test dataset? (2 significant digits)\n",
    "\n",
    "**Note:** The first index of ``predict_proba`` refers to the probability that the data belong to class 0, and the second refers to the probability that the data belong to class 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
