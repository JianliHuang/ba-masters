{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'> Project 1\n",
    "\n",
    "### Project description:\n",
    "- Please read the Data Set Information section to learn about this dataset. \n",
    "- Data description is also provided for thi dataset.\n",
    "- Read data into Jupyter notebook, use pandas to import data into a data frame\n",
    "- Preprocess data: Explore data, check for missing data and apply data scaling. Justify the type of scaling used.\n",
    "\n",
    "### Regression Task:\n",
    "- Apply all the regression models you've learned so far. If your model has a scaling parameter(s) use Grid Search to find the best scaling parameter. Use plots and graphs to help you get a better glimpse of the results. \n",
    "- Then use cross validation to find average training and testing score. \n",
    "- Your submission should have at least the following regression models: KNN repressor, linear regression, Ridge, Lasso, polynomial regression, SVM both simple and with kernels. \n",
    "- Finally find the best regressor for this dataset and train your model on the entire dataset using the best parameters and predict buzz for the test_set.\n",
    "\n",
    "### Classification task:\n",
    "- Decide aboute a good evaluation strategy and justify your choice.\n",
    "- Find best parameters for following classification models: KNN classifcation, Logistic Regression, Linear Supprt Vector Machine, Kerenilzed Support Vector Machine, Decision Tree. \n",
    "- Which model gives the best results?\n",
    "\n",
    "### Deliverables:\n",
    "- Submit IPython notebook. Use markdown to provide an inline comments for this project.\n",
    "- Submit only one notebook. Before submitting, make sure everything runs as expected. To check that, restart the kernel (in the menubar, select Kernel > Restart) and then run all cells (in the menubar, select Cell > Run All).\n",
    "- Visualization encouraged. \n",
    "\n",
    "### Questions regarding project:\n",
    "- Post your queries related to project on discussion board on e-learning. There is high possibility that your classmate has also faced the same problem and knows the solution. This is an effort to encourage collaborative learning and also making all the information available to everyone. We will also answer queries there. We will not be answering any project related queries through mail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data Set Information:\n",
    "This dataset is taken from a research explained here. \n",
    "\n",
    "The goal of the research is to help the auditors by building a classification model that can predict the fraudulent firm on the basis the present and historical risk factors. The information about the sectors and the counts of firms are listed respectively as Irrigation (114), Public Health (77), Buildings and Roads (82), Forest (70), Corporate (47), Animal Husbandry (95), Communication (1), Electrical (4), Land (5), Science and Technology (3), Tourism (1), Fisheries (41), Industries (37), Agriculture (200).\n",
    "\n",
    "There are two csv files to present data. Please merge these two datasets into one dataframe. All the steps should be done in Python. Please don't make any changes in csv files. Consider ``Audit_Risk`` as target columns for regression tasks, and ``Risk`` as the target column for classification tasks. \n",
    "\n",
    "### Attribute Information:\n",
    "Many risk factors are examined from various areas like past records of audit office, audit-paras, environmental conditions reports, firm reputation summary, on-going issues report, profit-value records, loss-value records, follow-up reports etc. After in-depth interview with the auditors, important risk factors are evaluated and their probability of existence is calculated from the present and past records.\n",
    "\n",
    "\n",
    "### Relevant Papers:\n",
    "Hooda, Nishtha, Seema Bawa, and Prashant Singh Rana. 'Fraudulent Firm Classification: A Case Study of an External Audit.' Applied Artificial Intelligence 32.1 (2018): 48-64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#raw_data = pd.read_csv('audit_risk.csv')\n",
    "d1 = pd.read_csv('audit_risk.csv')\n",
    "d2 = pd.read_csv('trial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d1.shape)\n",
    "print(d2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(d1),'\\n')\n",
    "print(list(d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sector_score: ',sum(d1['Sector_score']==d2['Sector_score']))\n",
    "print('LOCATION_ID: ',sum(d1['LOCATION_ID']==d2['LOCATION_ID']))\n",
    "print('PARA_A: ',sum(d1['PARA_A']==d2['PARA_A']))\n",
    "print('Score_A: ',sum(d1['Score_A']==d2['SCORE_A']))\n",
    "print('PARA_B: ',sum(d1['PARA_B']==d2['PARA_B']))\n",
    "print('Score_B: ',sum(d1['Score_B']==d2['SCORE_B']))\n",
    "print('TOTAL: ',sum(d1['TOTAL']==d2['TOTAL']))\n",
    "print('numbers: ',sum(d1['numbers']==d2['numbers']))\n",
    "print('Money_Value: ',sum(d1['Money_Value']==d2['Money_Value']))\n",
    "print('History: ',sum(d1['History']==d2['History']))\n",
    "print('Score: ',sum(d1['Score']==d2['Score']))\n",
    "print('Risk: ',sum(d1['Risk']==d2['Risk']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.drop(['Sector_score','LOCATION_ID','PARA_A','PARA_B','TOTAL','numbers','History','Score'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.concat([d1,d2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(raw_data.isnull().sum())\n",
    "np.where(a > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[raw_data.columns[12]].describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[raw_data.columns[12]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[pd.to_numeric(raw_data['LOCATION_ID'], errors='coerce').isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data[pd.to_numeric(raw_data['LOCATION_ID'], errors='coerce').notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating test and control groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = raw_data.drop(['Audit_Risk','Risk'],axis=1)\n",
    "y_reg = raw_data['Audit_Risk']\n",
    "y_class = raw_data['Risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# default is 75% / 25% train-test split\n",
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x, y_reg, random_state=0)\n",
    "x_train_class, x_test_class, y_train_class, y_test_class = train_test_split(x, y_class, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_train_reg = scaler.fit_transform(x_train_reg)\n",
    "x_test_reg = scaler.transform(x_test_reg)\n",
    "\n",
    "x_train_class = scaler.fit_transform(x_train_class)\n",
    "x_test_class = scaler.transform(x_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]}\n",
    "grid_search = GridSearchCV(knn, param_grid, scoring='recall_weighted', return_train_score=True)\n",
    "grid_search.fit(x_train_class, y_train_class.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "knn.fit(x_train_class, y_train_class)\n",
    "\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "y_train_predict = knn.predict(x_train_class)\n",
    "print('Accuracy of Training: {:.2f}'.format(accuracy_score(y_train_class, y_train_predict)))\n",
    "y_predict = knn.predict(x_test_class)\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test_class, y_predict)))\n",
    "print('Recall: {:.5f}'.format(recall_score(y_test_class, y_predict, average=\"weighted\")))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test_class, y_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
